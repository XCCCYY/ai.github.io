<!-- src/components/fragments/Step6Content.vue -->
<script setup>
import { onMounted, onUnmounted, ref } from 'vue'
import Live2DModel from '@/components/Live2DModel.vue'

// ÊòØÂê¶Ê≠£Âú®ËØ¥ËØù
const isTalking = ref(false)
// ÊòØÂê¶Ê≠£Âú®ÂÄæÂê¨
const isListening = ref(false)
// ÂØπËØùÂéÜÂè≤
const messages = ref([])

// Ê®°ÂûãÂÆû‰æãÂºïÁî®ÔºàÁî®‰∫éÊéßÂà∂Âä®‰ΩúÔºâ
let live2dModel = null

// ÂàùÂßãÂåñËØ≠Èü≥ËØÜÂà´
const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)()
recognition.lang = 'zh-CN'
recognition.continuous = true
recognition.interimResults = true

// ËØ≠Èü≥ÂêàÊàê
const synth = window.speechSynthesis

// ÂºÄÂßãËØ≠Èü≥ËØÜÂà´
const startListening = () => {
    isListening.value = true
    recognition.start()
}

// ÂÅúÊ≠¢ËØÜÂà´
const stopListening = () => {
    isListening.value = false
    recognition.stop()
}

// ÂèëÈÄÅÁî®Êà∑ËØ≠Èü≥Âà∞ÂêéÁ´ØÂπ∂Ëé∑ÂèñÂõûÂ§ç
// ‚úÖ Ê≠£Á°ÆÔºöË∞ÉÁî®‰Ω†Ëá™Â∑±ÁöÑÂêéÁ´Ø API
const sendToLLM = async (text) => {
    try {
        // ‚úÖ Êîπ‰∏∫Ë∞ÉÁî®Êú¨Âú∞ /api/chat
        const res = await fetch('/api/chat', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ message: text })
        })

        const data = await res.json()
        const reply = data.reply || 'ÊàëÊöÇÊó∂Êó†Ê≥ïËÅîÁΩëÔºå‰ΩÜÂæàÈ´òÂÖ¥ËßÅÂà∞‰Ω†ÔºÅ'

        // ‚úÖ Ê∑ªÂä†Âà∞ÂØπËØùÂéÜÂè≤
        messages.value.push({ role: 'user', content: text })
        messages.value.push({ role: 'ai', content: reply })

        // ‚úÖ ËÆ©Ê®°ÂûãËØ¥ËØù
        speak(reply)
    } catch (error) {
        console.error('Request failed:', error)
        const fallback = 'ÊàëÊöÇÊó∂Êó†Ê≥ïËÅîÁΩëÔºå‰ΩÜÂæàÈ´òÂÖ¥ËßÅÂà∞‰Ω†ÔºÅ'
        messages.value.push({ role: 'user', content: text })
        messages.value.push({ role: 'ai', content: fallback })
        speak(fallback)
    }
}

// Ê®°ÂûãËØ¥ËØù
const speak = (text) => {
    isTalking.value = true
    stopListening() // ÂÅúÊ≠¢ÁõëÂê¨

    const utterance = new SpeechSynthesisUtterance(text)
    utterance.lang = 'zh-CN'
    utterance.rate = 1 // ËØ≠ÈÄü
    utterance.pitch = 1 // Èü≥Ë∞É

    utterance.onstart = () => {
        // ÂºÄÂßãËØ¥ËØù ‚Üí Ëß¶ÂèëÂò¥ÂûãÂä®Áîª
        if (live2dModel) {
            live2dModel.startMouthMovement() // ÂÅáËÆæ Live2D ÊîØÊåÅÊ≠§ÊñπÊ≥ï
            live2dModel.setExpression('happy') // Ê†πÊçÆÂÜÖÂÆπË∞ÉÊï¥Ë°®ÊÉÖ
        }
    }

    utterance.onend = () => {
        isTalking.value = false
        // ËØ¥ÂÆåÂêéÁªßÁª≠ÁõëÂê¨
        startListening()
    }

    synth.speak(utterance)
}

// ÊåÇÊñ≠ÈÄöËØù
const hangUp = () => {
    stopListening()
    synth.cancel()
    // ÂõûÂà∞‰∏ªÁïåÈù¢
    window.history.back()
}

// ÁõëÂê¨ËØ≠Èü≥ËØÜÂà´ÁªìÊûú
recognition.onresult = (event) => {
    let finalTranscript = ''
    let interimTranscript = ''

    for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcript = event.results[i][0].transcript
        if (event.results[i].isFinal) {
            finalTranscript += transcript
        } else {
            interimTranscript += transcript
        }
    }

    if (finalTranscript) {
        sendToLLM(finalTranscript)
    }
}

// ÈîôËØØÂ§ÑÁêÜ
recognition.onerror = (event) => {
    console.warn('Speech recognition error', event.error)
}

// Ê®°ÂûãÂä†ËΩΩÂÆåÊàêÂõûË∞É
const onModelReady = (model) => {
    live2dModel = model
    // ÂèØ‰ª•ËÆæÁΩÆÂàùÂßãË°®ÊÉÖ
    live2dModel.setExpression('normal')
}

onMounted(() => {
    startListening()
})

onUnmounted(() => {
    stopListening()
    synth.cancel()
})
</script>

<template>
    <!-- ÂÖ®Â±èÈÄèÊòéÁéªÁíÉÂ±Ç -->
    <div class="glass-call-container">
        <!-- Live2D Ê®°ÂûãÂ±Ö‰∏≠ -->
        <div class="model-wrapper">
            <Live2DModel @ready="onModelReady" />
        </div>

        <!-- ÂØπËØùÂéÜÂè≤ÔºàÂèØÈÄâÊòæÁ§∫Ôºâ -->
        <div class="chat-history">
            <div v-for="(msg, index) in messages" :key="index" :class="['message', msg.role]">
                <strong>{{ msg.role === 'user' ? '‰Ω†' : 'ËßíËâ≤' }}:</strong> {{ msg.content }}
            </div>
        </div>

        <!-- ÊåÇÊñ≠ÊåâÈíÆ -->
        <button class="hang-up-btn" @click="hangUp">
            ÊåÇÊñ≠
        </button>

        <!-- Áä∂ÊÄÅÊåáÁ§∫ -->
        <div class="status-indicator">
            <span v-if="isListening">üéôÔ∏è ÂÄæÂê¨‰∏≠...</span>
            <span v-if="isTalking">üó£Ô∏è ËØ¥ËØù‰∏≠...</span>
        </div>
    </div>
</template>

<style scoped>
.glass-call-container {
    position: fixed;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    background-color: rgba(0, 0, 0, 0.7);
    backdrop-filter: blur(10px);
    display: flex;
    flex-direction: column;
    justify-content: center;
    align-items: center;
    z-index: 1000;
    color: white;
}

.model-wrapper {
    width: 400px;
    height: 500px;
    margin-bottom: 20px;
    position: relative;
    z-index: 1;
}

.chat-history {
    max-height: 200px;
    overflow-y: auto;
    width: 80%;
    font-size: 14px;
    opacity: 0.8;
    text-align: left;
    margin-bottom: 20px;
}

.message {
    margin: 4px 0;
    padding: 4px 8px;
    border-radius: 8px;
}

.message.user {
    background: rgba(255, 255, 255, 0.2);
}

.message.ai {
    background: rgba(100, 180, 255, 0.3);
}

.hang-up-btn {
    position: absolute;
    bottom: 40px;
    padding: 12px 30px;
    background: #ff4757;
    color: white;
    border: none;
    border-radius: 30px;
    font-size: 18px;
    cursor: pointer;
    box-shadow: 0 4px 10px rgba(0, 0, 0, 0.3);
}

.status-indicator {
    position: absolute;
    top: 40px;
    font-size: 18px;
    font-weight: bold;
}
</style>